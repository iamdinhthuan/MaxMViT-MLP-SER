dataset:
  root_dir: "AbstractTTS/IEMOCAP" # local path or HF ID
  batch_size: 32 # Adjust based on GPU memory
  num_workers: 16 # Adjust based on CPU cores
  target_size: [224, 224]

training:
  epochs: 50
  lr: 0.02
  patience: 5 # Early stopping patience
  scheduler:
    factor: 0.1
    patience: 2 # Reduce LR if no improvement for 2 epochs
    min_lr: 1e-6
  device: "cuda" # 'cuda' or 'cpu'

model:
  num_classes: 4 # neu, hap, ang, sad
